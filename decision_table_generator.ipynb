{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9-7rKgfPNe2V"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SifatSikder/decision-table-generator/blob/main/decision_table_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Library Imports**"
      ],
      "metadata": {
        "id": "9-7rKgfPNe2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install word2number"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74CFAdv93mk2",
        "outputId": "8aa513c8-3e22-497c-f20b-9cacbd2b272b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting word2number\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: word2number\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5567 sha256=de8ba4d2ed7d3c8ccd2dc398e7920dfa3a40d3c9212984b443c0b6d28821cf23\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/ff/26/d3cfbd971e96c5aa3737ecfced81628830d7359b55fbb8ca3b\n",
            "Successfully built word2number\n",
            "Installing collected packages: word2number\n",
            "Successfully installed word2number-1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5uFNrdhjC72r"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import itertools\n",
        "import re\n",
        "import string\n",
        "import pandas as pd\n",
        "import spacy\n",
        "\n",
        "from word2number import w2n\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inputs**"
      ],
      "metadata": {
        "id": "hMzafIw8hjIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"If the working hours are 48 or less then give normal salary.\",\n",
        "    \"The rate of the salary is 1.25 times if the working hours exceed 48 on normal working days.\",\n",
        "    \"If the working days are holidays or Sundays then the rate of the salary is 2.00 times.\"\n",
        "]\n",
        "# sentences = [\n",
        "#     \"If the order is from DGS&D then the discount is 10%.\",\n",
        "#     \"The discount is 15% if the order is from agents and the amount is more than Rs 50000.\",\n",
        "#     \"The discount is 10% if the order is from retailer and the amount is more than Rs 50000.\",\n",
        "#     \"If the amount is between Rs 20000 to Rs 50000 and the order is from agents then the discount is 12%.\",\n",
        "#     \"If the amount is between Rs 20000 to Rs 50000 and the order is from retailer then the discount is 8%.\",\n",
        "#     \"If the amount is less than Rs 20000 and the order is from agents then the discount is 8%.\",\n",
        "#     \"The discount is 5% if the order is from retailer and the amount is less than Rs 20000.\",\n",
        "#     \"The discount is 10% if item is furniture.\",\n",
        "# ]\n",
        "\n",
        "# sentences = [\n",
        "#     \"Students are eligible for normal course if marks in Java is greater than equal 70 and marks in C++ is greater than equal 60 and marks in OOAD is greater than equal 60 and in addition, total in all three subjects is greater than equal 220 or total in Java and C++ is greater than 150\",\n",
        "#     \"If total marks is greater than 240 then students are eligible for scholarship course\",\n",
        "# ]\n",
        "\n",
        "# excersice 11 page 142 pdf naresh\n",
        "# sentences = [\n",
        "#     \"If passenger travel more than 50,000 km. per calendar year and in addition, pay cash for tickets or have been traveling regularly for more than eight years then get a free round trip ticket around India.\",\n",
        "#     \"If Passenger travel less than 50,000 km. per calendar year and have been availing railway services regularly for more than eight years then get a free round ticket around India.\",\n",
        "# ]\n",
        "\n"
      ],
      "metadata": {
        "id": "x-cA8q5ehox3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Condition and action stubs generation**"
      ],
      "metadata": {
        "id": "4mQn-gUkKLfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_single_conditions(mixed_conditions):\n",
        "  mixed_conditions=[item.split(' and ') for item in mixed_conditions]\n",
        "  unique_conditions=[]\n",
        "  for conditions in mixed_conditions:\n",
        "    for condition in conditions:\n",
        "      unique_conditions.append(condition)\n",
        "  return unique_conditions\n",
        "\n",
        "def filter_unique(single_conditions):\n",
        "  unique_conditions = set()\n",
        "  for condition in single_conditions:\n",
        "    unique_conditions.add(condition)\n",
        "  return list(unique_conditions)\n",
        "\n",
        "def clean_data(dataset):\n",
        "  dataset=[data.lower() for data in dataset]\n",
        "  translator = str.maketrans('', '', string.punctuation)\n",
        "  return [data.translate(translator) for data in dataset]\n",
        "\n",
        "def cleaning_action_stubs(mixed_actions):\n",
        "  return filter_unique(clean_data(mixed_actions))\n",
        "\n",
        "def cleaning_condition_stubs(mixed_conditions):\n",
        "  single_conditions= create_single_conditions(clean_data(mixed_conditions))\n",
        "  return filter_unique(single_conditions)\n",
        "\n",
        "def cleaning_stubs(mixed_conditions,mixed_actions):\n",
        "  return cleaning_condition_stubs(mixed_conditions),cleaning_action_stubs(mixed_actions)\n",
        "\n",
        "def get_stubs(sentences):\n",
        "  condition_stub = []\n",
        "  action_stub = []\n",
        "  for sentence in sentences:\n",
        "      words = sentence.split()\n",
        "      if words[0].lower() == 'if':\n",
        "          condition_index = sentence.lower().index('if') + 2\n",
        "          then_index = sentence.lower().index('then')\n",
        "          condition_stub.append(sentence[condition_index:then_index].strip())\n",
        "          action_stub.append(sentence[then_index + 4:].strip())\n",
        "      else:\n",
        "          if_index = sentence.lower().index('if')\n",
        "          condition_stub.append(sentence[if_index + 2:].strip())\n",
        "          action_stub.append(sentence[:if_index].strip())\n",
        "\n",
        "  conditions,actions =(cleaning_stubs(condition_stub,action_stub))\n",
        "  return conditions,actions\n"
      ],
      "metadata": {
        "id": "3CcBR8loDvj9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(get_stubs(sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gm0tCNt8bCI",
        "outputId": "d3ce576d-7345-4acc-af10-a2e1d655e4cb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['the working hours exceed 48 on normal working days',\n",
              "  'the working hours are 48 or less',\n",
              "  'the working days are holidays or sundays'],\n",
              " ['the rate of the salary is 200 times',\n",
              "  'the rate of the salary is 125 times',\n",
              "  'give normal salary'])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Rule Generation**"
      ],
      "metadata": {
        "id": "sD1o6ZUL0ii9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_conditions_for_a_rule(mixed_condition,condition_stubs):\n",
        "  conditions_for_a_rule=[]\n",
        "\n",
        "  conditions=split_mixed_stub(mixed_condition)\n",
        "  for condition in conditions:\n",
        "    condition=condition.strip()\n",
        "    for index, condition_stub in enumerate(condition_stubs):\n",
        "      if condition in condition_stub:\n",
        "        conditions_for_a_rule.append(index)\n",
        "  return conditions_for_a_rule\n",
        "\n",
        "def get_actions_for_a_rule(mixed_action,action_stubs):\n",
        "  actions_for_a_rule=[]\n",
        "\n",
        "  actions=split_mixed_stub(mixed_action)\n",
        "  for action in actions:\n",
        "    action=action.strip()\n",
        "    for index, action_stub in enumerate(action_stubs):\n",
        "      if action in action_stub:\n",
        "        actions_for_a_rule.append(index)\n",
        "  return actions_for_a_rule\n",
        "\n",
        "def parse_sentence(sentence,if_then):\n",
        "  condition_index = sentence.index('if')\n",
        "  if(if_then):\n",
        "    then_index = sentence.index('then')\n",
        "    mixed_condition=sentence[condition_index+2:then_index].strip()\n",
        "    mixed_action=sentence[then_index + 4:].strip()\n",
        "  else:\n",
        "    mixed_condition=sentence[condition_index+2:].strip()\n",
        "    mixed_action=sentence[:condition_index].strip()\n",
        "  return mixed_condition,mixed_action\n",
        "\n",
        "def get_condition_and_action_from_sentence(sentence):\n",
        "  sentence=''.join(clean_data(sentence))\n",
        "  words = sentence.split()\n",
        "\n",
        "  if words[0] == 'if':\n",
        "    mixed_condition,mixed_action=parse_sentence(sentence,True)\n",
        "  else:\n",
        "    mixed_condition,mixed_action=parse_sentence(sentence,False)\n",
        "  return mixed_condition,mixed_action\n",
        "\n",
        "def split_mixed_stub(mixed_condition):\n",
        "  return mixed_condition.split('and')\n",
        "\n",
        "def create_rules(sentences,condition_stubs,action_stubs):\n",
        "\n",
        "  rules={}\n",
        "  rule=1\n",
        "  for sentence in sentences:\n",
        "\n",
        "    mixed_condition,mixed_action =  get_condition_and_action_from_sentence(sentence)\n",
        "    conditions_for_a_rule =   get_conditions_for_a_rule(mixed_condition,condition_stubs)\n",
        "    actions_for_a_rule =   get_actions_for_a_rule(mixed_action,action_stubs)\n",
        "\n",
        "    rules[rule]=[conditions_for_a_rule,actions_for_a_rule]\n",
        "    rule+=1\n",
        "  return rules\n"
      ],
      "metadata": {
        "id": "ok0bpxWCEraI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_rules(sentences,condition_stubs,action_stubs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klJyZQX68pGG",
        "outputId": "4cea2761-cd80-493e-e166-ba254c9c033c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: [[], []], 2: [[], []], 3: [[], []]}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Expression Generation**"
      ],
      "metadata": {
        "id": "zedyih34Dde-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prune_determinant(sentences):\n",
        "  pruned_sentences=[]\n",
        "  for sentence in sentences:\n",
        "    doc = nlp(sentence)\n",
        "    sentence = \" \".join([token.text for token in doc if token.pos_ != \"DET\"])\n",
        "    pruned_sentences.append(sentence)\n",
        "  return pruned_sentences\n",
        "\n",
        "def describe_parts_of_speech(sentence):\n",
        "  parts_of_speech={}\n",
        "  doc = nlp(sentence)\n",
        "  for token in doc:\n",
        "    parts_of_speech[token.text]=token.dep_\n",
        "  return parts_of_speech\n",
        "\n",
        "def noun_list(sentence):\n",
        "  nouns=[]\n",
        "  doc = nlp(sentence)\n",
        "  for token in doc:\n",
        "    if(token.pos_=='NOUN'):\n",
        "      nouns.append(token.text)\n",
        "  return nouns\n",
        "\n",
        "def find_variable_name(sentence):\n",
        "  doc = nlp(sentence)\n",
        "  for token in doc:\n",
        "    if(token.pos_=='NOUN'):\n",
        "      return token.text\n",
        "  return 'No Noun Found'\n",
        "\n",
        "# TODO ADD PATTERNS\n",
        "def find_patterns(sentence):\n",
        "  matcher = Matcher(nlp.vocab)\n",
        "\n",
        "  between_pattern = [\n",
        "      {\"LOWER\": \"between\"},\n",
        "      {\"OP\": \"*\"},\n",
        "      {\"LOWER\": \"to\"}\n",
        "  ]\n",
        "\n",
        "  more_than_pattern = [\n",
        "      {\"LOWER\": \"more\"},\n",
        "      {\"LOWER\": \"than\"}\n",
        "  ]\n",
        "  # greater_than_pattern = [\n",
        "  #     {\"LOWER\": \"greater\"},\n",
        "  #     {\"LOWER\": \"than\"}\n",
        "  # ]\n",
        "\n",
        "  # less_than_pattern = [\n",
        "  #     {\"LOWER\": \"less\"},\n",
        "  #     {\"LOWER\": \"than\"}\n",
        "  # ]\n",
        "\n",
        "  greater_than_pattern = [{\"LOWER\": {\"IN\": [\"greater\", \"more\", \"bigger\", \"larger\"]}},\n",
        "                         {\"LOWER\": {\"IN\": [\"than\", \"then\", \"that\"]}}]\n",
        "  less_than_pattern = [{\"LOWER\": {\"IN\": [\"less\", \"fewer\", \"smaller\"]}},\n",
        "                      {\"LOWER\": {\"IN\": [\"than\", \"then\", \"that\"]}}]\n",
        "\n",
        "  is_are_pattern = [\n",
        "      {\"LOWER\": {\"IN\": [\"is\", \"are\"]},\n",
        "      }\n",
        "  ]\n",
        "  is_not_equal_pattern = [\n",
        "      {\"LOWER\": {\"IN\": [\"is not equal\"]},\n",
        "      }\n",
        "  ]\n",
        "\n",
        "  # Adding new patterns to the matcher\n",
        "  greater_than_equal_pattern = [{\"LOWER\": {\"IN\": [\"greater than or equal\", \"more than or equal\", \"bigger than or equal\", \"larger than or equal\",\n",
        "                                                  \"greater than or same\", \"more than or same\", \"bigger than or same\", \"larger than or same\"]}}]\n",
        "  less_than_equal_pattern = [{\"LOWER\": {\"IN\": [\"less than or equal\", \"fewer than or equal\", \"smaller than or equal\", \"lesser than or equal\",\n",
        "                                                  \"less than or same\", \"fewer than or same\", \"smaller than or same\", \"lesser than or same\"]}}]\n",
        "\n",
        "  # equal_pattern = [{\"LOWER\": {\"IN\": [\"equal\", \"=\"]}}]\n",
        "  greater_than_pattern = [{\"LOWER\": \"greater\"}, {\"LOWER\": \"than\"}]\n",
        "  less_than_pattern = [{\"LOWER\": \"less\"}, {\"LOWER\": \"than\"}]\n",
        "\n",
        "  # Adding new patterns to the Matcher\n",
        "  # matcher.add(\"equal\", [equal_pattern])\n",
        "\n",
        "  matcher.add(\"greater_than_equal\", [greater_than_equal_pattern])\n",
        "  matcher.add(\"less_than_equal\", [less_than_equal_pattern])\n",
        "\n",
        "\n",
        "  matcher.add(\"is_are\", [is_are_pattern])\n",
        "  matcher.add(\"between_to\", [between_pattern])\n",
        "  # matcher.add(\"more_than\", [more_than_pattern])\n",
        "  matcher.add(\"greater_than\", [greater_than_pattern])\n",
        "  matcher.add(\"less_than\", [less_than_pattern])\n",
        "  matcher.add(\"is_not_equal\", [is_not_equal_pattern])\n",
        "\n",
        "  doc = nlp(sentence)\n",
        "  matches = matcher(doc)\n",
        "  matcher_names=[]\n",
        "  if matches:\n",
        "    for match_id, start, end in matches:\n",
        "        matched_text = doc[start:end].text\n",
        "        matcher_names.append(doc.vocab.strings[match_id])\n",
        "\n",
        "\n",
        "  return (matcher_names)\n",
        "\n",
        "def find_sign(sentence):\n",
        "  sign=\"\"\n",
        "\n",
        "  # Amount is less than 20000rs [\"is_are\",\"less_than\"]\n",
        "  #expression : amount = <20000\n",
        "  # Amount is 20000rs [\"is_are\"]\n",
        "  #expression : amount = 20000\n",
        "  patterns=find_patterns(sentence)\n",
        "  for pattern in patterns:\n",
        "    if(pattern=='is_are'):\n",
        "      sign+='='\n",
        "    elif(pattern=='greater_than'):\n",
        "      sign+='>'\n",
        "    elif(pattern=='greater_than_equal'):\n",
        "      sign+='>='\n",
        "    elif(pattern=='less_than_equal'):\n",
        "      sign+='<='\n",
        "    elif(pattern=='less_than'):\n",
        "      sign+='<'\n",
        "    elif(pattern=='between_to'):\n",
        "      temp=[]\n",
        "      doc= nlp(sentence)\n",
        "      for token in doc:\n",
        "        if(token.tag_=='CD'): temp.append(w2n.word_to_num(token.text))\n",
        "      sign+=str(temp)\n",
        "  if sign==\"\": return 'No Sign Found'\n",
        "  else : return sign\n",
        "\n",
        "def find_value_of_a_variable(sentence):\n",
        "  value=[]\n",
        "  doc=nlp(sentence)\n",
        "  if 'between' not in sentence:\n",
        "    for token in doc:\n",
        "      if (token.dep_=='pobj' or token.dep_=='dobj' or token.dep_=='nummod'or token.dep_=='attr') :\n",
        "        value.append(token.text)\n",
        "    return str(value)\n",
        "  return ''\n",
        "\n",
        "def convert_to_expression(sentence):\n",
        "  # patterns = [\n",
        "  #   (r'is between (\\d+) (to|and) (\\d+)', r'\\1 < amount < \\3'),\n",
        "  #   (r'is between (\\d+) and (\\d+)', r'<\\1 and >\\2'),\n",
        "  #   (r'is between (\\d+) to (\\d+)', r'<\\1 and >\\2'),\n",
        "\n",
        "  #   (r'are between (\\d+) and (\\d+)', r'<\\1 and >\\2'),\n",
        "  #   (r'are between (\\d+) to (\\d+)', r'<\\1 and >\\2'),\n",
        "\n",
        "  #   (r'\\bor less\\b', '<='),\n",
        "  #   (r'\\bless than or equal to\\b', '<='),\n",
        "  #   (r'\\bless than\\b', '<'),\n",
        "\n",
        "  #   (r'\\bor more\\b', '>='),\n",
        "  #   (r'\\bmore than or equal to\\b', '>='),\n",
        "  #   (r'\\bmore than\\b', '>'),\n",
        "\n",
        "  #   (r'\\bor greater\\b', '>='),\n",
        "  #   (r'\\bgreater than or equal to\\b', '>='),\n",
        "  #   (r'\\bgreater than\\b', '>'),\n",
        "\n",
        "\n",
        "  #   (r'\\bis not equal to\\b', '!='),\n",
        "  #   (r'\\bis equal to\\b', '='),\n",
        "  #   (r'\\bis\\b', '='),\n",
        "\n",
        "  #   (r'\\bare not equal to\\b', '!='),\n",
        "  #   (r'\\bare equal to\\b', '='),\n",
        "  #   (r'\\bare\\b', '='),\n",
        "  # ]\n",
        "\n",
        "  expression=''\n",
        "  expression+=find_variable_name(sentence)\n",
        "  expression+=find_sign(sentence)\n",
        "  expression+=find_value_of_a_variable(sentence)\n",
        "  return expression\n",
        "\n",
        "def get_expressions(condition_stubs,action_stubs):\n",
        "  condition_stubs=prune_determinant(condition_stubs)\n",
        "  action_stubs=prune_determinant(action_stubs)\n",
        "  condition_stubs_expressions=[]\n",
        "  action_stubs_expressions=[]\n",
        "  for condition in condition_stubs:\n",
        "    condition_stubs_expressions.append(convert_to_expression(condition))\n",
        "  for action in action_stubs:\n",
        "    action_stubs_expressions.append(convert_to_expression(action))\n",
        "  return  condition_stubs_expressions,action_stubs_expressions\n",
        "\n",
        "def find_unique_variables(condition_stubs_expressions):\n",
        "  unique_variable = {}\n",
        "  for expression in condition_stubs_expressions:\n",
        "      variable, value = expression.split('=')\n",
        "      unique_variable[variable] = value\n",
        "  unique_variables=list(unique_variable.keys())\n",
        "  return unique_variables\n",
        "\n",
        "def create_dependency_dictionary(condition_stubs,condition_stubs_expressions):\n",
        "  unique_variables=find_unique_variables(condition_stubs_expressions)\n",
        "  dependencies={}\n",
        "  for variable in unique_variables:\n",
        "    conditions=[]\n",
        "    i=1\n",
        "    for condition in condition_stubs:\n",
        "      if(variable==find_variable_name(condition)):\n",
        "        conditions.append(i)\n",
        "      i+=1\n",
        "    dependencies[variable]=conditions\n",
        "  return dependencies\n"
      ],
      "metadata": {
        "id": "lfOzDH04y9xV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Table Generation**"
      ],
      "metadata": {
        "id": "1vpNRAjW8H-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_column_headers(rules):\n",
        "  column_headers = []\n",
        "  for i in rules:\n",
        "    column_header=\"R\"+str(i)\n",
        "    column_headers.append(column_header)\n",
        "  return column_headers\n",
        "\n",
        "def make_row_headers(condition_stubs,action_stubs):\n",
        "  row_headers = []\n",
        "\n",
        "  for index,condition_stub in enumerate(condition_stubs):\n",
        "    row_header=\"C\"+str(index+1)+\":\"+str(condition_stub)\n",
        "    row_headers.append(row_header)\n",
        "\n",
        "  for index,action_stub in enumerate(action_stubs):\n",
        "    row_header=\"A\"+str(index+1)+\":\"+str(action_stub)\n",
        "    row_headers.append(row_header)\n",
        "\n",
        "  return row_headers\n",
        "\n",
        "def make_table(condition_stubs,action_stubs,rules):\n",
        "  column_headers=make_column_headers(rules)\n",
        "  row_headers=make_row_headers(condition_stubs,action_stubs)\n",
        "  table = pd.DataFrame(columns=column_headers, index=row_headers)\n",
        "  return table\n",
        "\n",
        "def initialize_table(table):\n",
        "  for row in table.index:\n",
        "      if(row.startswith('C')):\n",
        "        for col in table.columns:\n",
        "                table.at[row, col] = 'I'\n",
        "      else:\n",
        "        for col in table.columns:\n",
        "          table.at[row, col] = ' '\n",
        "  return table\n",
        "\n",
        "def adjust_dependent_entries(table,condition,condition_stubs,col):\n",
        "  dependencies=dependency_dictionary[find_variable_name(condition_stubs[condition])]\n",
        "  for dependency_condition in dependencies:\n",
        "    for row in table.index:\n",
        "      if(row.startswith('C') and dependency_condition!=condition+1 and int(row[1])==dependency_condition):\n",
        "        table.at[row,col] ='F'\n",
        "\n",
        "def set_condition_stubs_entries(table,rules,condition_stubs):\n",
        "  for i in range(1,len(table.columns)+1):\n",
        "    condition_set=(rules[i][0])\n",
        "    for condition in condition_set:\n",
        "      for row in table.index:\n",
        "        if(row.startswith('C') and int(row[1])==condition+1):\n",
        "          col=table.columns[i-1]\n",
        "          table.at[row,col] ='T'\n",
        "          adjust_dependent_entries(table,condition,condition_stubs,col)\n",
        "  return table\n",
        "\n",
        "def set_action_stubs_entries(table,rules):\n",
        "  for i in range(1,len(table.columns)+1):\n",
        "    action_set=(rules[i][1])\n",
        "    for action in action_set:\n",
        "      for row in table.index:\n",
        "        if(row.startswith('A') and int(row[1])==action+1):\n",
        "          col=table.columns[i-1]\n",
        "          table.at[row,col] ='x'\n",
        "  return table\n",
        "\n",
        "def find_independent_rows(table,number_of_conditions,rules):\n",
        "  independent_rows=[]\n",
        "  for column_name, conditions in table.items():\n",
        "    number_of_truths=0\n",
        "    number_of_ignores=0\n",
        "    for condition in conditions:\n",
        "      if(condition=='T'): number_of_truths+=1\n",
        "      elif(condition=='I'): number_of_ignores+=1\n",
        "    if(number_of_truths==1 and number_of_ignores==number_of_conditions-1):\n",
        "      independent_rows.append(rules[int(column_name[1])][0][0])\n",
        "  return independent_rows\n",
        "\n",
        "def optimize_table(table,number_of_conditions,rules):\n",
        "  independent_rows=find_independent_rows(table,number_of_conditions,rules)\n",
        "  for independent_row in independent_rows:\n",
        "    i=0\n",
        "    for row_name, row_data in table.iterrows():\n",
        "      if(i==independent_row):\n",
        "        for col_index,data in enumerate(row_data):\n",
        "          if(data!='T'): table.iat[independent_row, col_index]='F'\n",
        "      i+=1\n",
        "\n",
        "def generate_table(condition_stubs,action_stubs,rules):\n",
        "  table=initialize_table(make_table(condition_stubs,action_stubs,rules))\n",
        "  table=set_action_stubs_entries(table,rules)\n",
        "  table=set_condition_stubs_entries(table,rules,condition_stubs)\n",
        "  optimize_table(table,len(condition_stubs),rules)\n",
        "  return table\n",
        "\n",
        "def printDetails(condition_stubs,action_stubs,rules,table):\n",
        "  print(\"Rules are: \")\n",
        "  for rule in rules:\n",
        "\n",
        "    mixed_condition=\"\"\n",
        "    for condition in rules[rule][0]:\n",
        "      mixed_condition+=condition_stubs[condition]\n",
        "      mixed_condition+=','\n",
        "\n",
        "\n",
        "    mixed_action=\"\"\n",
        "    for action in rules[rule][1]:\n",
        "      mixed_action+=action_stubs[action]\n",
        "      mixed_action+=','\n",
        "    print(str(rule)+\":\"+\"If \"+mixed_condition+\"then \"+mixed_action)\n"
      ],
      "metadata": {
        "id": "MeLJ9R7t8HWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test case table Generation**"
      ],
      "metadata": {
        "id": "vhHmkBok8Ryt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_test_case_table(table):\n",
        "  for row in table.index:\n",
        "    for col in table.columns:\n",
        "      table.at[row, col] = 'any'\n",
        "  return table\n",
        "\n",
        "def make_test_case_table(dependency_dictionary,rules):\n",
        "  column_headers=list(dependency_dictionary.keys())\n",
        "  column_headers.append('Expected Output')\n",
        "\n",
        "  row_headers=[]\n",
        "  for i in range(1,len(rules)+1):\n",
        "    row_headers.append(i)\n",
        "  test_case_table = pd.DataFrame(columns=column_headers, index=row_headers)\n",
        "  return initialize_test_case_table(test_case_table)\n",
        "\n",
        "def fill_test_case_inputs(test_case_table,condition_stubs_expressions,rules):\n",
        "  for index,rule in enumerate(rules.values()):\n",
        "    row_label=index+1\n",
        "    for condition in rule[0]:\n",
        "      splited_expression=condition_stubs_expressions[condition].split('=')\n",
        "      col_label=(splited_expression[0])\n",
        "      test_case_table.at[index+1,col_label]=splited_expression[1]\n",
        "  return test_case_table\n",
        "\n",
        "def fill_expected_output_section(test_case_table,action_stubs,rules):\n",
        "  last_column=test_case_table.columns[-1]\n",
        "  index=1\n",
        "  for rule in rules.values():\n",
        "    test_case_table.at[index, last_column] = (action_stubs[rule[1][0]])\n",
        "    index+=1\n",
        "  return (test_case_table)\n",
        "\n",
        "def generate_test_case_table(rules,condition_stubs,condition_stubs_expressions,action_stubs,dependency_dictionary):\n",
        "  test_case_table =make_test_case_table(dependency_dictionary,rules)\n",
        "  test_case_table=fill_test_case_inputs(test_case_table,condition_stubs_expressions,rules)\n",
        "  test_case_table=fill_expected_output_section(test_case_table,action_stubs,rules)\n",
        "  return test_case_table\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "t29SvpXy7ulS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Driver**"
      ],
      "metadata": {
        "id": "OuDF6dHn5Mb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "condition_stubs,action_stubs=get_stubs(sentences)\n",
        "rules=create_rules(sentences,condition_stubs,action_stubs)\n",
        "condition_stubs_expressions,action_stubs_expressions=get_expressions(condition_stubs,action_stubs)\n",
        "dependency_dictionary=create_dependency_dictionary(condition_stubs,condition_stubs_expressions)\n",
        "table=generate_table(condition_stubs,action_stubs,rules)\n",
        "test_case_table=generate_test_case_table(rules,condition_stubs,condition_stubs_expressions,action_stubs,dependency_dictionary)\n",
        "\n",
        "printDetails(condition_stubs,action_stubs,rules,table)\n",
        "print()\n",
        "print()\n",
        "print('===================================DECISION TABLE===================================')\n",
        "print()\n",
        "print(table)\n",
        "print()\n",
        "print('===================================TEST CASE TABLE===================================')\n",
        "print()\n",
        "print(test_case_table)"
      ],
      "metadata": {
        "id": "Zrbhr3xd5O6Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "05986a33-2e8e-41bd-9a2b-bda073045026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-108486971207>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_rules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcondition_stubs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction_stubs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcondition_stubs_expressions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction_stubs_expressions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_expressions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition_stubs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction_stubs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdependency_dictionary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_dependency_dictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition_stubs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcondition_stubs_expressions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerate_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition_stubs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction_stubs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtest_case_table\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerate_test_case_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrules\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcondition_stubs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcondition_stubs_expressions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction_stubs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdependency_dictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-10afc53684aa>\u001b[0m in \u001b[0;36mcreate_dependency_dictionary\u001b[0;34m(condition_stubs, condition_stubs_expressions)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_dependency_dictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition_stubs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcondition_stubs_expressions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m   \u001b[0munique_variables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_unique_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition_stubs_expressions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m   \u001b[0mdependencies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mvariable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munique_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-10afc53684aa>\u001b[0m in \u001b[0;36mfind_unique_variables\u001b[0;34m(condition_stubs_expressions)\u001b[0m\n\u001b[1;32m    159\u001b[0m   \u001b[0munique_variable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mexpression\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcondition_stubs_expressions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m       \u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m       \u001b[0munique_variable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0munique_variables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_variable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
          ]
        }
      ]
    }
  ]
}